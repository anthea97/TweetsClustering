{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Part 2: Tweets Clustering Using k-means\n",
        "\n",
        "Dataset: https://archive.ics.uci.edu/dataset/438/health+news+in+twitter\n",
        "\n",
        "File: bbchealth.txt\n",
        "\n",
        "References:\n"
      ],
      "metadata": {
        "id": "TMuDUA7KAt_P"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preprocessing"
      ],
      "metadata": {
        "id": "IX2OgnRNRUtq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "\n",
        "data = requests.get('https://raw.githubusercontent.com/anthea97/TweetsClustering/main/bbchealth.txt')\n",
        "tweets = data.text.split('\\n')"
      ],
      "metadata": {
        "id": "_f9i_T0fqWmk"
      },
      "execution_count": 93,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tweets[:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tFWGO9DMrQQo",
        "outputId": "be51f37a-ea82-4dc7-e39d-8a587062b9a5"
      },
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['585978391360221184|Thu Apr 09 01:31:50 +0000 2015|Breast cancer risk test devised http://bbc.in/1CimpJF\\r',\n",
              " '585947808772960257|Wed Apr 08 23:30:18 +0000 2015|GP workload harming care - BMA poll http://bbc.in/1ChTBRv\\r',\n",
              " \"585947807816650752|Wed Apr 08 23:30:18 +0000 2015|Short people's 'heart risk greater' http://bbc.in/1ChTANp\\r\",\n",
              " \"585866060991078401|Wed Apr 08 18:05:28 +0000 2015|New approach against HIV 'promising' http://bbc.in/1E6jAjt\\r\",\n",
              " \"585794106170839041|Wed Apr 08 13:19:33 +0000 2015|Coalition 'undermined NHS' - doctors http://bbc.in/1CnLwK7\\r\"]"
            ]
          },
          "metadata": {},
          "execution_count": 94
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Number of tweets: \", len(tweets))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CpcdIcjyzFTx",
        "outputId": "dcf37ea0-e2c4-405f-d05f-eb942a323b75"
      },
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of tweets:  3929\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "only_tweets = []\n",
        "\n",
        "for tweet in tweets:\n",
        "  sections = tweet.split('|')\n",
        "  only_tweets.append(sections[2])\n",
        "\n",
        "only_tweets[:5]\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Vis2UmSS4h-",
        "outputId": "9346d12c-40d2-41ee-9aaa-edeaf63491fb"
      },
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Breast cancer risk test devised http://bbc.in/1CimpJF\\r',\n",
              " 'GP workload harming care - BMA poll http://bbc.in/1ChTBRv\\r',\n",
              " \"Short people's 'heart risk greater' http://bbc.in/1ChTANp\\r\",\n",
              " \"New approach against HIV 'promising' http://bbc.in/1E6jAjt\\r\",\n",
              " \"Coalition 'undermined NHS' - doctors http://bbc.in/1CnLwK7\\r\"]"
            ]
          },
          "metadata": {},
          "execution_count": 96
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Remove the tweet id and timestamp\n",
        "#Remove any word that starts with the symbol @ e.g. @AnnaMedaris\n",
        "#Remove any hashtag symbols e.g. convert #depression to depression\n",
        "#Remove any URL\n",
        "#Convert every word to lowercase\n",
        "\n",
        "import re\n",
        "\n",
        "for i, tweet in enumerate(only_tweets):\n",
        "  tweet = re.sub(r'\\B@\\w+\\b', '', tweet)\n",
        "  tweet = re.sub(r'#', '', tweet)\n",
        "  tweet = re.sub(r'\\n', '', tweet)\n",
        "  tweet = re.sub(r'\\r', '', tweet)\n",
        "  tweet = re.sub(r'http\\S+|www\\S+', '', tweet)\n",
        "\n",
        "  tweet = tweet.lower()\n",
        "  only_tweets[i] = tweet\n",
        "\n",
        "only_tweets[:10]\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PEeIN8R4S53b",
        "outputId": "a43fcafb-06d2-4d80-ab57-04a91445684e"
      },
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['breast cancer risk test devised ',\n",
              " 'gp workload harming care - bma poll ',\n",
              " \"short people's 'heart risk greater' \",\n",
              " \"new approach against hiv 'promising' \",\n",
              " \"coalition 'undermined nhs' - doctors \",\n",
              " 'review of case against nhs manager ',\n",
              " \"video: 'all day is empty, what am i going to do?' \",\n",
              " \"video: 'overhaul needed' for end-of-life care \",\n",
              " \"care for dying 'needs overhaul' \",\n",
              " 'video: nhs: labour and tory key policies ']"
            ]
          },
          "metadata": {},
          "execution_count": 97
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Convert each tweet to an unordered set of words\n",
        "processed_tweets = [set(tweet.split()) for tweet in only_tweets]\n",
        "processed_tweets[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NIhAa2-02SxW",
        "outputId": "f9e38a97-c159-4522-c08a-6d58fdafd9ec"
      },
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'breast', 'cancer', 'devised', 'risk', 'test'},\n",
              " {'-', 'bma', 'care', 'gp', 'harming', 'poll', 'workload'},\n",
              " {\"'heart\", \"greater'\", \"people's\", 'risk', 'short'},\n",
              " {\"'promising'\", 'against', 'approach', 'hiv', 'new'},\n",
              " {\"'undermined\", '-', 'coalition', 'doctors', \"nhs'\"},\n",
              " {'against', 'case', 'manager', 'nhs', 'of', 'review'},\n",
              " {\"'all\",\n",
              "  'am',\n",
              "  'day',\n",
              "  \"do?'\",\n",
              "  'empty,',\n",
              "  'going',\n",
              "  'i',\n",
              "  'is',\n",
              "  'to',\n",
              "  'video:',\n",
              "  'what'},\n",
              " {\"'overhaul\", 'care', 'end-of-life', 'for', \"needed'\", 'video:'},\n",
              " {\"'needs\", 'care', 'dying', 'for', \"overhaul'\"},\n",
              " {'and', 'key', 'labour', 'nhs:', 'policies', 'tory', 'video:'}]"
            ]
          },
          "metadata": {},
          "execution_count": 98
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## K-Means Algorithm From Scratch"
      ],
      "metadata": {
        "id": "mhCEeRR61jsA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import statistics\n",
        "\n",
        "class KMeans:\n",
        "  def __init__(self, k = 3, max_iter = 10):\n",
        "    self.k = k\n",
        "    self.max_iter = max_iter\n",
        "    self.centroids = None\n",
        "\n",
        "  def jaccard_distance(self, set_a, set_b):\n",
        "    num = set_a.intersection(set_b)\n",
        "    den = set_a.union(set_b)\n",
        "\n",
        "    return 1-(len(num)/len(den))\n",
        "\n",
        "  def clusterize(self, data, centroids):\n",
        "      cluster_dict = {}\n",
        "\n",
        "      for doc in data:\n",
        "        distances = []\n",
        "        for centroid in centroids:\n",
        "          distances.append(self.jaccard_distance(doc, centroid))\n",
        "\n",
        "        min_distance = distances.index(min(distances))\n",
        "        cluster_dict.setdefault(min_distance, [])\n",
        "        cluster_dict[min_distance].append(doc)\n",
        "\n",
        "      return cluster_dict\n",
        "\n",
        "  def calculate_centroid(self, data):\n",
        "    candidates_dict = {}\n",
        "\n",
        "    for doc_i in data:\n",
        "      distances = []\n",
        "      for doc_j in data:\n",
        "        distances.append(self.jaccard_distance(doc_i, doc_j))\n",
        "      #find the average of all jaccard distances for doc_i\n",
        "      # note: getting the same result with statistics.mean and sum - using sum for faster processing\n",
        "      avg_distance = sum(distances)\n",
        "      candidates_dict.setdefault(tuple(doc_i), 1)\n",
        "      candidates_dict[tuple(doc_i)] = avg_distance\n",
        "\n",
        "    #Return the candidate that has the least average jaccard distance\n",
        "    centroid = min(candidates_dict, key = candidates_dict.get)\n",
        "\n",
        "    return set(centroid)\n",
        "\n",
        "  def fit(self, data):\n",
        "    #Randomly select k clusters\n",
        "    data = np.array(data)\n",
        "    random_indices = np.random.choice(len(data), self.k, replace=False)\n",
        "    self.centroids = data[random_indices]\n",
        "\n",
        "    for _ in range(self.max_iter):\n",
        "      new_centroids = []\n",
        "      clusters = self.clusterize(data, self.centroids)\n",
        "\n",
        "      for doc_set in clusters:\n",
        "        new_centroids.append(self.calculate_centroid(clusters[doc_set]))\n",
        "\n",
        "      if np.array_equal(self.centroids, new_centroids):\n",
        "        break\n",
        "\n",
        "      self.centroids = new_centroids\n",
        "\n",
        "    return new_centroids, clusters\n",
        "\n",
        "\n",
        "  def SSE(self, clusters, centroids):\n",
        "    sse = 0\n",
        "\n",
        "    for (key, value) in clusters.items():\n",
        "      centroid = centroids[key]\n",
        "      cluster_sum = 0\n",
        "      for x in value:\n",
        "        d = self.jaccard_distance(x, centroid)\n",
        "        dist = d**2\n",
        "        cluster_sum += dist\n",
        "\n",
        "      sse += cluster_sum\n",
        "    return sse\n",
        "\n",
        "\n",
        "  def cluster_size(self, clusters):\n",
        "    length = []\n",
        "    for i, cluster in enumerate(clusters):\n",
        "      print(len(clusters[i]))\n",
        "      length.append(len(clusters[i]))\n",
        "\n",
        "    return length\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ow-IJ4eyVvna"
      },
      "execution_count": 99,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "object = KMeans(k=5, max_iter = 20)"
      ],
      "metadata": {
        "id": "pwvHrYL67PX2"
      },
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "centroids, clusters = object.fit(processed_tweets)"
      ],
      "metadata": {
        "id": "OhsSO6YKu6wZ"
      },
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sse = object.SSE(clusters, centroids)"
      ],
      "metadata": {
        "id": "I7Uf_Duu5UAe"
      },
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(sse)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b6nZPeGnx1WB",
        "outputId": "fdbd27e3-289a-4bd1-b84a-d6b5c2397265"
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3351.609247325381\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "object.cluster_size(clusters)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YhVMQ71ZyOGk",
        "outputId": "9b8abdb0-96d9-4f86-ec2c-6e10b2fa1dc6"
      },
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1762\n",
            "829\n",
            "424\n",
            "537\n",
            "377\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1762, 829, 424, 537, 377]"
            ]
          },
          "metadata": {},
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##"
      ],
      "metadata": {
        "id": "WGTTXXWL1f7m"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Compute for different values of k"
      ],
      "metadata": {
        "id": "D2Bs9Gdh1m6v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "k_values = [3, 5, 10, 15, 20]\n",
        "cluster_sizes = {}\n",
        "sse_values = {}"
      ],
      "metadata": {
        "id": "bho6fcsM1cRv"
      },
      "execution_count": 101,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for k in k_values:\n",
        "  print(\"k = \", k, \"start\")\n",
        "  model_k = KMeans(k=k)\n",
        "  centroids, clusters = model_k.fit(processed_tweets)\n",
        "  csize = model_k.cluster_size(clusters)\n",
        "  cluster_sizes.setdefault(k, [])\n",
        "  cluster_sizes[k] = csize\n",
        "  sse = model_k.SSE(clusters, centroids)\n",
        "  sse_values.setdefault(k, [])\n",
        "  sse_values[k] = sse\n",
        "  print(\"k = \", k, \"end\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RzTHj_GTzp06",
        "outputId": "581396ed-56f2-4c3a-8934-1e5783a30ad4"
      },
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "k =  3 start\n",
            "2784\n",
            "480\n",
            "665\n",
            "k =  3 end\n",
            "k =  5 start\n",
            "1791\n",
            "804\n",
            "601\n",
            "426\n",
            "307\n",
            "k =  5 end\n",
            "k =  10 start\n",
            "1294\n",
            "398\n",
            "89\n",
            "677\n",
            "239\n",
            "488\n",
            "202\n",
            "409\n",
            "118\n",
            "15\n",
            "k =  10 end\n",
            "k =  15 start\n",
            "1333\n",
            "340\n",
            "81\n",
            "138\n",
            "241\n",
            "47\n",
            "307\n",
            "31\n",
            "461\n",
            "528\n",
            "101\n",
            "72\n",
            "70\n",
            "49\n",
            "130\n",
            "k =  15 end\n",
            "k =  20 start\n",
            "1078\n",
            "129\n",
            "36\n",
            "285\n",
            "454\n",
            "361\n",
            "276\n",
            "127\n",
            "240\n",
            "104\n",
            "184\n",
            "43\n",
            "150\n",
            "211\n",
            "24\n",
            "75\n",
            "58\n",
            "53\n",
            "37\n",
            "4\n",
            "k =  20 end\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "from google.colab import drive\n",
        "\n",
        "#comment if not running for the first time\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "file_path = '/content/drive/My Drive/output.csv'\n",
        "\n",
        "with open(file_path, 'w', newline='') as file:\n",
        "    writer = csv.writer(file)\n",
        "\n",
        "    writer.writerow([\"k\", \"SSE\", \"Cluster Sizes\"])\n",
        "\n",
        "    for k in k_values:\n",
        "        writer.writerow([k, sse_values[k], cluster_sizes[k]])\n",
        "\n"
      ],
      "metadata": {
        "id": "ZXV_wDUpFclX"
      },
      "execution_count": 108,
      "outputs": []
    }
  ]
}